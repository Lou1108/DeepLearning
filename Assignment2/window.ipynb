{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization,DepthwiseConv2D\n",
    "from tensorflow.keras.layers import Activation,AveragePooling2D,Conv2D, RepeatVector, Permute, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tcn import TCN\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (64, 248, 35624)\n",
      "Shape of y_train: (64,)\n",
      "Shape of X_test1: (16, 248, 35624)\n",
      "Uniqe labels: [0 1 2 3]\n",
      "Number of training samples: 64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import glob # Used to find all file paths\n",
    "import os\n",
    "\n",
    "BASE_PATH = 'Final Project data/Cross'\n",
    "\n",
    "TRAIN_DIR = os.path.join(BASE_PATH, 'train/')\n",
    "TEST1_DIR = os.path.join(BASE_PATH, 'test1/')\n",
    "TEST2_DIR = os.path.join(BASE_PATH, 'test2/')\n",
    "TEST3_DIR = os.path.join(BASE_PATH, 'test3/')\n",
    "\n",
    "# Each file has 248 sensor readings (rows) and 35624 time steps (columns)\n",
    "N_CHANNELS = 248\n",
    "N_TIMESTEPS = 35624\n",
    "\n",
    "# The 4 states we want to classify\n",
    "TASKS = ['rest', 'task_motor', 'task_story_math', 'task_working_memory']\n",
    "# Map tasks to integer labels\n",
    "task_to_label = {task: i for i, task in enumerate(TASKS)}\n",
    "\n",
    "# Function to load data from a list of file paths\n",
    "def load_data(file_paths):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for file_path in file_paths:\n",
    "        # Extractin the label\n",
    "        filename = file_path.split('/')[-1]\n",
    "\n",
    "        #handling the different task naming conventions\n",
    "        if 'rest' in filename:\n",
    "            labels.append(task_to_label['rest'])\n",
    "        elif 'motor' in filename:\n",
    "            labels.append(task_to_label['task_motor'])\n",
    "        elif 'story' in filename or 'math' in filename:\n",
    "             labels.append(task_to_label['task_story_math'])\n",
    "        elif 'working' in filename or 'memory' in filename:\n",
    "            labels.append(task_to_label['task_working_memory'])\n",
    "        else:\n",
    "            # iff a file doesn't match\n",
    "            print(f\"Could not determine task for file: {filename}\")\n",
    "            continue\n",
    "\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # Instead of guessing the dataset name, we get the first key from the file\n",
    "            # This is robust because we know there is only one dataset per file[cite: 10].\n",
    "            dataset_name = list(f.keys())[0]\n",
    "            matrix = f[dataset_name][()]\n",
    "            data.append(matrix)\n",
    "\n",
    "    #convert to numpy arrays\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "train_files = glob.glob(f\"{TRAIN_DIR}/*.h5\")\n",
    "test1_files = glob.glob(f\"{TEST1_DIR}/*.h5\")\n",
    "test2_files = glob.glob(f\"{TEST2_DIR}/*.h5\")\n",
    "test3_files = glob.glob(f\"{TEST3_DIR}/*.h5\")\n",
    "intra_file = glob.glob(f\"{os.path.join('Final Project data/Intra', 'train/')}/*.h5\")\n",
    "\n",
    "\n",
    "X_train, y_train = load_data(train_files)\n",
    "X_test1, y_test1 = load_data(test1_files)\n",
    "X_test2, y_test2 = load_data(test2_files)\n",
    "X_test3, y_test3 = load_data(test3_files)\n",
    "\n",
    "X_train_intra, y_train_intra = load_data(intra_file)\n",
    "\n",
    "\n",
    "# X_train = np.concatenate((X_train, X_train_intra), axis=0)\n",
    "# y_train = np.concatenate((y_train, y_train_intra), axis=0)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test1: {X_test1.shape}\")\n",
    "print(f\"Uniqe labels: {np.unique(y_train)}\")\n",
    "print(f\"Number of training samples: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of time steps: 35624\n",
      "Downsampled number of time steps: 3563\n",
      "\n",
      "Normalizing data...\n",
      "Normalization complete.\n",
      "Final shape of training data for the model: (64, 3563, 248)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler ,Normalizer ,MinMaxScaler\n",
    "\n",
    "\n",
    "# --- Downsampling ---\n",
    "# The original sample rate is 2034Hz\n",
    "#take every 10th sample\n",
    "DOWNSAMPLE_FACTOR = 10\n",
    "X_train_ds = X_train[:, :, ::DOWNSAMPLE_FACTOR]\n",
    "X_test1_ds = X_test1[:, :, ::DOWNSAMPLE_FACTOR]\n",
    "X_test2_ds = X_test2[:, :, ::DOWNSAMPLE_FACTOR]\n",
    "X_test3_ds = X_test3[:, :, ::DOWNSAMPLE_FACTOR]\n",
    "\n",
    "N_TIMESTEPS_DS = X_train_ds.shape[2]\n",
    "print(f\"Original number of time steps: {N_TIMESTEPS}\")\n",
    "print(f\"Downsampled number of time steps: {N_TIMESTEPS_DS}\")\n",
    "\n",
    "\n",
    "# --- Time-wise Normalization ---\n",
    "#normalize each channel's time-series independently.\n",
    "\n",
    "\n",
    "def normalize_data(data):\n",
    "    # Data shape is (n_samples, n_channels, n_timesteps)\n",
    "    # We want to scale each of the (n_samples * n_channels) time series\n",
    "\n",
    "    # Reshape to (n_samples * n_channels, n_timesteps) to apply StandardScaler\n",
    "    n_samples, n_channels, n_timesteps = data.shape\n",
    "    reshaped_data = data.reshape(n_samples * n_channels, n_timesteps)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(reshaped_data)\n",
    "\n",
    "    # Reshape back to the original shape\n",
    "    return scaled_data.reshape(n_samples, n_channels, n_timesteps)\n",
    "\n",
    "print(\"\\nNormalizing data...\")\n",
    "X_train_norm = normalize_data(X_train_ds)\n",
    "X_test1_norm = normalize_data(X_test1_ds)\n",
    "X_test2_norm = normalize_data(X_test2_ds)\n",
    "X_test3_norm = normalize_data(X_test3_ds)\n",
    "\n",
    "#DL models in Keras often expect the channel dimension last\n",
    "#reshaping from (samples, channels, timesteps) to (samples, timesteps, channels)\n",
    "X_train_final = np.transpose(X_train_norm, (0, 2, 1))\n",
    "X_test1_final = np.transpose(X_test1_norm, (0, 2, 1))\n",
    "X_test2_final = np.transpose(X_test2_norm, (0, 2, 1))\n",
    "X_test3_final = np.transpose(X_test3_norm, (0, 2, 1))\n",
    "\n",
    "print(\"Normalization complete.\")\n",
    "print(f\"Final shape of training data for the model: {X_train_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of augmented training data: (128, 3563, 248)\n",
      "-32.417206147174326 7.267772900866241\n"
     ]
    }
   ],
   "source": [
    "def add_noise(data, noise_factor=0.05):\n",
    "    noise = np.random.normal(loc=0.0, scale=noise_factor, size=data.shape)\n",
    "    return data + noise\n",
    "\n",
    "def scale_amplitude(data, scale_factor_range=(0.9, 1.1)):\n",
    "    scaler = np.random.uniform(low=scale_factor_range[0], high=scale_factor_range[1])\n",
    "    return data * scaler\n",
    "\n",
    "\n",
    "X_train_augmented = []\n",
    "y_train_augmented = []\n",
    "\n",
    "for i in range(len(X_train_final)):\n",
    "    original_sample = X_train_final[i]\n",
    "    original_label = y_train[i]\n",
    "\n",
    "    X_train_augmented.append(original_sample)\n",
    "    y_train_augmented.append(original_label)\n",
    "\n",
    "    augmented_sample = add_noise(original_sample)\n",
    "    augmented_sample = scale_amplitude(augmented_sample)\n",
    "    X_train_augmented.append(augmented_sample)\n",
    "    y_train_augmented.append(original_label)\n",
    "\n",
    "\n",
    "# Convert the lists back to numpy arrays\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)\n",
    "print(f\"Shape of augmented training data: {X_train_augmented.shape}\")\n",
    "\n",
    "print(X_train_augmented.min(), X_train_augmented.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(X, y, window_size=200, step_size=100):\n",
    "    \"\"\"\n",
    "    Create overlapping windows of shape (window_size, channels) from each trial.\n",
    "    Input shape: (samples, timesteps, channels)\n",
    "    Output shape: (num_windows, window_size, channels)\n",
    "    \"\"\"\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "    for i in range(int(X.shape[0])):  # iterate over samples\n",
    "        sample = X[i]  # (timesteps, channels)\n",
    "        label = y[i]\n",
    "        for start in range(0, sample.shape[0] - window_size + 1, step_size):\n",
    "            end = start + window_size\n",
    "            X_windows.append(sample[start:end])\n",
    "            y_windows.append(label)\n",
    "\n",
    "    return np.array(X_windows), np.array(y_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def make_objective(build_model_fn):\n",
    "    def objective(trial):\n",
    "        # Suggest window and step sizes\n",
    "        window_size = trial.suggest_int(\"window_size\", 100, 400, step=50)\n",
    "        step_size = trial.suggest_int(\"step_size\", 50, 300, step=25)\n",
    "\n",
    "        # Re-window the data\n",
    "        X_train_win, y_train_win = window_data(X_train_augmented, y_train_augmented, window_size, step_size)\n",
    "        X_test1_win, y_test1_win = window_data(X_test1_final, y_test1, window_size, step_size)\n",
    "        X_test2_win, y_test2_win = window_data(X_test2_final, y_test2, window_size, step_size)\n",
    "        X_test3_win, y_test3_win = window_data(X_test3_final, y_test3, window_size, step_size)\n",
    "\n",
    "        NUM_CLASSES = len(np.unique(y_train_win))\n",
    "\n",
    "        # Avoid invalid shapes\n",
    "        if X_train_win.shape[1] != window_size:\n",
    "            return 0.0\n",
    "\n",
    "        input_shape = (window_size, X_train_win.shape[2])\n",
    "        model = build_model_fn(input_shape, NUM_CLASSES)  # Flexible model passed here\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train for a few epochs (quick tuning)\n",
    "        model.fit(X_train_win, y_train_win, batch_size=32, epochs=5, validation_split=0.2, verbose=0)\n",
    "\n",
    "        # Evaluate\n",
    "        _, acc1 = model.evaluate(X_test1_win, y_test1_win, verbose=0)\n",
    "        _, acc2 = model.evaluate(X_test2_win, y_test2_win, verbose=0)\n",
    "        _, acc3 = model.evaluate(X_test3_win, y_test3_win, verbose=0)\n",
    "        avg_acc = (acc1 + acc2 + acc3) / 3\n",
    "\n",
    "        return avg_acc\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-15 12:23:17,357] A new study created in memory with name: no-name-28e2fb29-a24d-40ab-8382-53d47bc7967e\n",
      "[I 2025-06-15 12:23:29,355] Trial 0 finished with value: 0.6970238188902537 and parameters: {'window_size': 125, 'step_size': 100}. Best is trial 0 with value: 0.6970238188902537.\n",
      "[I 2025-06-15 12:23:45,212] Trial 1 finished with value: 0.6209935943285624 and parameters: {'window_size': 350, 'step_size': 125}. Best is trial 0 with value: 0.6970238188902537.\n",
      "[I 2025-06-15 12:23:57,406] Trial 2 finished with value: 0.6758578419685364 and parameters: {'window_size': 200, 'step_size': 100}. Best is trial 0 with value: 0.6970238188902537.\n",
      "[I 2025-06-15 12:24:27,080] Trial 3 finished with value: 0.6540767351786295 and parameters: {'window_size': 100, 'step_size': 25}. Best is trial 0 with value: 0.6970238188902537.\n",
      "[I 2025-06-15 12:24:37,743] Trial 4 finished with value: 0.6349637707074484 and parameters: {'window_size': 250, 'step_size': 150}. Best is trial 0 with value: 0.6970238188902537.\n",
      "[I 2025-06-15 12:24:51,507] Trial 5 finished with value: 0.7376893957455953 and parameters: {'window_size': 375, 'step_size': 150}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:25:06,147] Trial 6 finished with value: 0.71059783299764 and parameters: {'window_size': 175, 'step_size': 75}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:25:15,071] Trial 7 finished with value: 0.6851190626621246 and parameters: {'window_size': 125, 'step_size': 100}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:26:00,537] Trial 8 finished with value: 0.5986922184626261 and parameters: {'window_size': 150, 'step_size': 25}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:26:55,975] Trial 9 finished with value: 0.6701899568239847 and parameters: {'window_size': 175, 'step_size': 25}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:27:12,030] Trial 10 finished with value: 0.7064393957455953 and parameters: {'window_size': 400, 'step_size': 150}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:27:33,429] Trial 11 finished with value: 0.6832386453946432 and parameters: {'window_size': 300, 'step_size': 75}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:27:51,254] Trial 12 finished with value: 0.7370370328426361 and parameters: {'window_size': 250, 'step_size': 75}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:28:22,738] Trial 13 finished with value: 0.6208964685599009 and parameters: {'window_size': 275, 'step_size': 50}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:28:35,763] Trial 14 finished with value: 0.6931089659531912 and parameters: {'window_size': 325, 'step_size': 125}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:28:59,513] Trial 15 finished with value: 0.6287313401699066 and parameters: {'window_size': 225, 'step_size': 50}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:29:14,315] Trial 16 finished with value: 0.7267628212769827 and parameters: {'window_size': 375, 'step_size': 125}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:29:32,416] Trial 17 finished with value: 0.7211174269517263 and parameters: {'window_size': 275, 'step_size': 75}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:30:08,289] Trial 18 finished with value: 0.6685897409915924 and parameters: {'window_size': 325, 'step_size': 50}. Best is trial 5 with value: 0.7376893957455953.\n",
      "[I 2025-06-15 12:30:21,509] Trial 19 finished with value: 0.7291666865348816 and parameters: {'window_size': 400, 'step_size': 150}. Best is trial 5 with value: 0.7376893957455953.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'window_size': 375, 'step_size': 150}\n",
      "Best accuracy: 73.77%\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">158,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2944</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">376,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m158,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m375\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_40 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_41 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m82,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_41 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_20 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2944\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m376,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">619,076</span> (2.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m619,076\u001b[0m (2.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">618,692</span> (2.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m618,692\u001b[0m (2.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "71/71 - 3s - 38ms/step - accuracy: 0.9618 - loss: 0.1474 - val_accuracy: 0.8936 - val_loss: 0.4491\n",
      "Epoch 2/20\n",
      "71/71 - 2s - 30ms/step - accuracy: 0.9991 - loss: 0.0018 - val_accuracy: 0.9291 - val_loss: 0.1569\n",
      "Epoch 3/20\n",
      "71/71 - 2s - 30ms/step - accuracy: 0.9960 - loss: 0.0123 - val_accuracy: 0.9823 - val_loss: 0.0565\n",
      "Epoch 4/20\n",
      "71/71 - 2s - 30ms/step - accuracy: 0.9973 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 4.2273e-10\n",
      "Epoch 5/20\n",
      "71/71 - 2s - 32ms/step - accuracy: 0.9929 - loss: 0.0593 - val_accuracy: 0.8121 - val_loss: 1.4831\n",
      "Epoch 6/20\n",
      "71/71 - 2s - 30ms/step - accuracy: 0.9933 - loss: 0.0616 - val_accuracy: 0.9805 - val_loss: 0.2269\n",
      "Epoch 7/20\n",
      "71/71 - 2s - 31ms/step - accuracy: 0.9893 - loss: 0.0988 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/20\n",
      "71/71 - 2s - 32ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/20\n",
      "71/71 - 2s - 34ms/step - accuracy: 0.9991 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/20\n",
      "71/71 - 2s - 31ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/20\n",
      "71/71 - 2s - 34ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/20\n",
      "71/71 - 2s - 33ms/step - accuracy: 0.9991 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/20\n",
      "71/71 - 2s - 32ms/step - accuracy: 1.0000 - loss: 3.4180e-06 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/20\n",
      "71/71 - 2s - 34ms/step - accuracy: 1.0000 - loss: 6.8874e-05 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/20\n",
      "71/71 - 2s - 31ms/step - accuracy: 0.9991 - loss: 0.0057 - val_accuracy: 0.9858 - val_loss: 0.0576\n",
      "Epoch 16/20\n",
      "71/71 - 2s - 33ms/step - accuracy: 0.9969 - loss: 0.0232 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/20\n",
      "71/71 - 2s - 33ms/step - accuracy: 0.9978 - loss: 0.0124 - val_accuracy: 0.9787 - val_loss: 0.4712\n",
      "Epoch 18/20\n",
      "71/71 - 2s - 32ms/step - accuracy: 0.9942 - loss: 0.0653 - val_accuracy: 1.0000 - val_loss: 1.0568e-09\n",
      "Epoch 19/20\n",
      "71/71 - 2s - 32ms/step - accuracy: 0.9947 - loss: 0.0823 - val_accuracy: 1.0000 - val_loss: 1.0568e-09\n",
      "Epoch 20/20\n",
      "71/71 - 2s - 34ms/step - accuracy: 0.9951 - loss: 0.0930 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "simple_cnn Model Accuracy on Test Set 1: 88.64%\n",
      "simple_cnn Model Accuracy on Test Set 2: 43.18%\n",
      "simple_cnn Model Accuracy on Test Set 3: 70.17%\n",
      "Average accuracy: 67.33%\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Evaluation\n",
      "[[88  0  0  0]\n",
      " [ 0 88  0  0]\n",
      " [ 0  0 88  0]\n",
      " [ 0 16 24 48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       0.85      1.00      0.92        88\n",
      "           2       0.79      1.00      0.88        88\n",
      "           3       1.00      0.55      0.71        88\n",
      "\n",
      "    accuracy                           0.89       352\n",
      "   macro avg       0.91      0.89      0.88       352\n",
      "weighted avg       0.91      0.89      0.88       352\n",
      "\n",
      "Loss: 17.3643, Accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv1D(filters=64, kernel_size=10, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=4),\n",
    "        Conv1D(filters=128, kernel_size=10, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=4),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(make_objective(build_cnn_model), n_trials=20)\n",
    "\n",
    "study.\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(f\"Best accuracy: {study.best_value * 100:.2f}%\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "# Re-window the data\n",
    "X_train_win, y_train_win = window_data(X_train_augmented, y_train_augmented, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test1_win, y_test1_win = window_data(X_test1_final, y_test1, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test2_win, y_test2_win = window_data(X_test2_final, y_test2, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test3_win, y_test3_win = window_data(X_test3_final, y_test3, study.best_params['window_size'], study.best_params['step_size'])\n",
    "\n",
    "NUM_CLASSES = len(np.unique(y_train_win))\n",
    "\n",
    "INPUT_SHAPE = (study.best_params['window_size'], X_train_win.shape[2])\n",
    "\n",
    "simple_cnn = build_cnn_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "\n",
    "simple_cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "simple_cnn.summary()\n",
    "\n",
    "# --- Training ---\n",
    "simple_cnn.fit(\n",
    "    X_train_win,\n",
    "    y_train_win,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on test sets\n",
    "loss1_simple_cnn, acc1_simple_cnn = simple_cnn.evaluate(X_test1_win, y_test1_win, verbose=0)\n",
    "print(f\"simple_cnn Model Accuracy on Test Set 1: {acc1_simple_cnn * 100:.2f}%\")\n",
    "loss2_simple_cnn, acc2_simple_cnn = simple_cnn.evaluate(X_test2_win, y_test2_win, verbose=0)\n",
    "print(f\"simple_cnn Model Accuracy on Test Set 2: {acc2_simple_cnn * 100:.2f}%\")\n",
    "loss3_simple_cnn, acc3_simple_cnn = simple_cnn.evaluate(X_test3_win, y_test3_win, verbose=0)\n",
    "print(f\"simple_cnn Model Accuracy on Test Set 3: {acc3_simple_cnn * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average accuracy: {((acc1_simple_cnn + acc2_simple_cnn +acc3_simple_cnn)/3) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "y_pred_probs = simple_cnn.predict(X_test1_win)\n",
    "\n",
    "# 2. Convert to class labels (e.g., 0, 1, 2, 3)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(\"Evaluation\")\n",
    "print(confusion_matrix(y_test1_win, y_pred))\n",
    "print(classification_report(y_test1_win, y_pred))\n",
    "loss, acc = simple_cnn.evaluate(X_test1_win, y_test1_win, verbose=0)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_cnn Model Accuracy on Test Set 1: 88.64%\n",
      "simple_cnn Model Accuracy on Test Set 2: 43.18%\n",
      "simple_cnn Model Accuracy on Test Set 3: 70.17%\n",
      "Average accuracy: 67.33%\n",
      "Evaluation for test 1\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        88\n",
      "           1       0.85      1.00      0.92        88\n",
      "           2       0.79      1.00      0.88        88\n",
      "           3       1.00      0.55      0.71        88\n",
      "\n",
      "    accuracy                           0.89       352\n",
      "   macro avg       0.91      0.89      0.88       352\n",
      "weighted avg       0.91      0.89      0.88       352\n",
      "\n",
      "Evaluation for test 2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        88\n",
      "           1       0.42      0.73      0.53        88\n",
      "           2       0.00      0.00      0.00        88\n",
      "           3       0.00      0.00      0.00        88\n",
      "\n",
      "    accuracy                           0.43       352\n",
      "   macro avg       0.34      0.43      0.38       352\n",
      "weighted avg       0.34      0.43      0.38       352\n",
      "\n",
      "Evaluation for test 3\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        88\n",
      "           1       0.42      0.50      0.46        88\n",
      "           2       0.71      0.31      0.43        88\n",
      "           3       1.00      1.00      1.00        88\n",
      "\n",
      "    accuracy                           0.70       352\n",
      "   macro avg       0.71      0.70      0.68       352\n",
      "weighted avg       0.71      0.70      0.68       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Evaluate on test sets\n",
    "loss1_simple_cnn, acc1_simple_cnn = simple_cnn.evaluate(X_test1_win, y_test1_win, verbose=0)\n",
    "print(f\"simple_cnn Model Accuracy on Test Set 1: {acc1_simple_cnn * 100:.2f}%\")\n",
    "loss2_simple_cnn, acc2_simple_cnn = simple_cnn.evaluate(X_test2_win, y_test2_win, verbose=0)\n",
    "print(f\"simple_cnn Model Accuracy on Test Set 2: {acc2_simple_cnn * 100:.2f}%\")\n",
    "loss3_simple_cnn, acc3_simple_cnn = simple_cnn.evaluate(X_test3_win, y_test3_win, verbose=0)\n",
    "print(f\"simple_cnn Model Accuracy on Test Set 3: {acc3_simple_cnn * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average accuracy: {((acc1_simple_cnn + acc2_simple_cnn +acc3_simple_cnn)/3) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Evaluation for test 1\")\n",
    "y_pred_probs = simple_cnn.predict(X_test1_win)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "# print(confusion_matrix(y_test1_win, y_pred))\n",
    "report1 = classification_report(y_test1_win, y_pred)\n",
    "print(report1)\n",
    "\n",
    "print(\"Evaluation for test 2\")\n",
    "y_pred_probs = simple_cnn.predict(X_test2_win)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "# print(confusion_matrix(y_test2_win, y_pred))\n",
    "report1 =classification_report(y_test2_win, y_pred)\n",
    "print(report1)\n",
    "\n",
    "print(\"Evaluation for test 3\")\n",
    "y_pred_probs = simple_cnn.predict(X_test3_win)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "# print(confusion_matrix(y_test3_win, y_pred))\n",
    "report1 =classification_report(y_test3_win, y_pred)\n",
    "print(report1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-15 13:10:40,502] A new study created in memory with name: no-name-e39632b6-22cd-4514-ac98-7c9928a1f24b\n",
      "[I 2025-06-15 13:11:05,820] Trial 0 finished with value: 0.6171296238899231 and parameters: {'window_size': 225, 'step_size': 75}. Best is trial 0 with value: 0.6171296238899231.\n",
      "[I 2025-06-15 13:11:15,741] Trial 1 finished with value: 0.5464285711447397 and parameters: {'window_size': 100, 'step_size': 100}. Best is trial 0 with value: 0.6171296238899231.\n",
      "[I 2025-06-15 13:11:36,134] Trial 2 finished with value: 0.7137681245803833 and parameters: {'window_size': 125, 'step_size': 50}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:11:43,918] Trial 3 finished with value: 0.6547619104385376 and parameters: {'window_size': 100, 'step_size': 125}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:12:07,265] Trial 4 finished with value: 0.6829427083333334 and parameters: {'window_size': 375, 'step_size': 100}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:12:32,659] Trial 5 finished with value: 0.6569010416666666 and parameters: {'window_size': 375, 'step_size': 100}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:12:52,132] Trial 6 finished with value: 0.7043269276618958 and parameters: {'window_size': 375, 'step_size': 125}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:15:42,423] Trial 7 finished with value: 0.6782051225503286 and parameters: {'window_size': 325, 'step_size': 25}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:16:39,915] Trial 8 finished with value: 0.657998780409495 and parameters: {'window_size': 150, 'step_size': 25}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:16:53,208] Trial 9 finished with value: 0.6571969787279764 and parameters: {'window_size': 275, 'step_size': 150}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:17:23,260] Trial 10 finished with value: 0.669117659330368 and parameters: {'window_size': 200, 'step_size': 50}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:17:36,871] Trial 11 finished with value: 0.6212121347586314 and parameters: {'window_size': 300, 'step_size': 150}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:18:02,867] Trial 12 finished with value: 0.6976102987925211 and parameters: {'window_size': 175, 'step_size': 50}. Best is trial 2 with value: 0.7137681245803833.\n",
      "[I 2025-06-15 13:18:25,392] Trial 13 finished with value: 0.7453703582286835 and parameters: {'window_size': 250, 'step_size': 75}. Best is trial 13 with value: 0.7453703582286835.\n",
      "[I 2025-06-15 13:19:04,744] Trial 14 finished with value: 0.7145522435506185 and parameters: {'window_size': 250, 'step_size': 50}. Best is trial 13 with value: 0.7453703582286835.\n",
      "[I 2025-06-15 13:19:28,232] Trial 15 finished with value: 0.6500000158945719 and parameters: {'window_size': 250, 'step_size': 75}. Best is trial 13 with value: 0.7453703582286835.\n",
      "[I 2025-06-15 13:19:55,163] Trial 16 finished with value: 0.7059659163157145 and parameters: {'window_size': 325, 'step_size': 75}. Best is trial 13 with value: 0.7453703582286835.\n",
      "[I 2025-06-15 13:20:26,779] Trial 17 finished with value: 0.7416044672330221 and parameters: {'window_size': 225, 'step_size': 50}. Best is trial 13 with value: 0.7453703582286835.\n",
      "[I 2025-06-15 13:21:38,355] Trial 18 finished with value: 0.6669752995173136 and parameters: {'window_size': 200, 'step_size': 25}. Best is trial 13 with value: 0.7453703582286835.\n",
      "[I 2025-06-15 13:22:05,305] Trial 19 finished with value: 0.6467803120613098 and parameters: {'window_size': 275, 'step_size': 75}. Best is trial 13 with value: 0.7453703582286835.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'window_size': 250, 'step_size': 75}\n",
      "Best accuracy: 74.54%\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">158,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_40          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_41          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m158,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_40          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_40 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_41 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m82,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_41          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_41 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_20 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">390,212</span> (1.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m390,212\u001b[0m (1.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">389,828</span> (1.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m389,828\u001b[0m (1.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "144/144 - 5s - 34ms/step - accuracy: 0.9796 - loss: 0.0736 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 2/20\n",
      "144/144 - 4s - 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9905 - val_loss: 0.0203\n",
      "Epoch 3/20\n",
      "144/144 - 4s - 27ms/step - accuracy: 1.0000 - loss: 3.3385e-04 - val_accuracy: 0.9887 - val_loss: 0.0270\n",
      "Epoch 4/20\n",
      "144/144 - 4s - 27ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9913 - val_loss: 0.0439\n",
      "Epoch 5/20\n",
      "144/144 - 4s - 27ms/step - accuracy: 0.9928 - loss: 0.0238 - val_accuracy: 1.0000 - val_loss: 1.2630e-04\n",
      "Epoch 6/20\n",
      "144/144 - 4s - 28ms/step - accuracy: 0.9967 - loss: 0.0139 - val_accuracy: 0.9931 - val_loss: 0.0341\n",
      "Epoch 7/20\n",
      "144/144 - 4s - 29ms/step - accuracy: 1.0000 - loss: 4.8691e-04 - val_accuracy: 0.9957 - val_loss: 0.0137\n",
      "Epoch 8/20\n",
      "144/144 - 4s - 27ms/step - accuracy: 1.0000 - loss: 3.1066e-04 - val_accuracy: 1.0000 - val_loss: 5.3194e-06\n",
      "Epoch 9/20\n",
      "144/144 - 4s - 28ms/step - accuracy: 1.0000 - loss: 1.1818e-04 - val_accuracy: 1.0000 - val_loss: 3.1517e-06\n",
      "Epoch 10/20\n",
      "144/144 - 4s - 29ms/step - accuracy: 0.9993 - loss: 0.0012 - val_accuracy: 0.9818 - val_loss: 0.0403\n",
      "Epoch 11/20\n",
      "144/144 - 4s - 31ms/step - accuracy: 0.9998 - loss: 0.0014 - val_accuracy: 0.9939 - val_loss: 0.0304\n",
      "Epoch 12/20\n",
      "144/144 - 4s - 29ms/step - accuracy: 1.0000 - loss: 1.2200e-04 - val_accuracy: 0.9931 - val_loss: 0.0389\n",
      "Epoch 13/20\n",
      "144/144 - 4s - 29ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 14/20\n",
      "144/144 - 4s - 31ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 2.4093e-05\n",
      "Epoch 15/20\n",
      "144/144 - 4s - 30ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 1.3720e-04\n",
      "Epoch 16/20\n",
      "144/144 - 4s - 28ms/step - accuracy: 0.9991 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 7.3335e-06\n",
      "Epoch 17/20\n",
      "144/144 - 4s - 28ms/step - accuracy: 1.0000 - loss: 1.8194e-04 - val_accuracy: 1.0000 - val_loss: 2.9032e-06\n",
      "Epoch 18/20\n",
      "144/144 - 4s - 29ms/step - accuracy: 1.0000 - loss: 9.7867e-05 - val_accuracy: 1.0000 - val_loss: 1.4722e-06\n",
      "Epoch 19/20\n",
      "144/144 - 5s - 32ms/step - accuracy: 0.9959 - loss: 0.0304 - val_accuracy: 1.0000 - val_loss: 1.2477e-05\n",
      "Epoch 20/20\n",
      "144/144 - 4s - 28ms/step - accuracy: 0.9991 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 2.5597e-05\n",
      "Hybrid Model Accuracy on Test Set 1: 100.00%\n",
      "Hybrid Model Accuracy on Test Set 2: 25.00%\n",
      "Hybrid Model Accuracy on Test Set 3: 81.25%\n",
      "Average accuracy: 68.75%\n"
     ]
    }
   ],
   "source": [
    "#Hybrid CNN-LSTM Model Architecture\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "def build_cnn_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "\n",
    "        # Convolutional layers to extract features\n",
    "        Conv1D(filters=64, kernel_size=10, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=4),\n",
    "\n",
    "        Conv1D(filters=128, kernel_size=10, activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=4),\n",
    "\n",
    "        # LSTM layer to model temporal sequences of the extracted features\n",
    "        LSTM(128, return_sequences=False), # return_sequences=False  it's the last recurrent layer\n",
    "\n",
    "        # Dense layers for classification\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(make_objective(build_cnn_lstm_model), n_trials=20)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(f\"Best accuracy: {study.best_value * 100:.2f}%\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Re-window the data\n",
    "X_train_win, y_train_win = window_data(X_train_augmented, y_train_augmented, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test1_win, y_test1_win = window_data(X_test1_final, y_test1, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test2_win, y_test2_win = window_data(X_test2_final, y_test2, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test3_win, y_test3_win = window_data(X_test3_final, y_test3, study.best_params['window_size'], study.best_params['step_size'])\n",
    "\n",
    "NUM_CLASSES = len(np.unique(y_train_win))\n",
    "\n",
    "INPUT_SHAPE = (study.best_params['window_size'], X_train_win.shape[2])\n",
    "\n",
    "cnn_lstm_model = build_cnn_lstm_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "\n",
    "cnn_lstm_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "# --- Training ---\n",
    "cnn_lstm_model.fit(\n",
    "    X_train_win,\n",
    "    y_train_win,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on test sets\n",
    "loss1_hybrid, acc1_hybrid = cnn_lstm_model.evaluate(X_test1_final, y_test1, verbose=0)\n",
    "print(f\"Hybrid Model Accuracy on Test Set 1: {acc1_hybrid * 100:.2f}%\")\n",
    "loss2_hybrid, acc2_hybrid = cnn_lstm_model.evaluate(X_test2_final, y_test2, verbose=0)\n",
    "print(f\"Hybrid Model Accuracy on Test Set 2: {acc2_hybrid * 100:.2f}%\")\n",
    "loss3_hybrid, acc3_hybrid = cnn_lstm_model.evaluate(X_test3_final, y_test3, verbose=0)\n",
    "print(f\"Hybrid Model Accuracy on Test Set 3: {acc3_hybrid * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average accuracy: {((acc1_hybrid + acc2_hybrid +acc3_hybrid)/3) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-15 13:26:20,400] A new study created in memory with name: no-name-45762589-bb58-42ca-9fc3-a20a94a93160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-15 13:26:35,665] Trial 0 finished with value: 0.672839492559433 and parameters: {'window_size': 200, 'step_size': 125}. Best is trial 0 with value: 0.672839492559433.\n",
      "[I 2025-06-15 13:26:47,421] Trial 1 finished with value: 0.658482164144516 and parameters: {'window_size': 175, 'step_size': 125}. Best is trial 0 with value: 0.672839492559433.\n",
      "[I 2025-06-15 13:27:09,743] Trial 2 finished with value: 0.6314102411270142 and parameters: {'window_size': 375, 'step_size': 125}. Best is trial 0 with value: 0.672839492559433.\n",
      "[I 2025-06-15 13:27:24,545] Trial 3 finished with value: 0.686887244383494 and parameters: {'window_size': 200, 'step_size': 100}. Best is trial 3 with value: 0.686887244383494.\n",
      "[I 2025-06-15 13:27:34,734] Trial 4 finished with value: 0.6785714328289032 and parameters: {'window_size': 150, 'step_size': 125}. Best is trial 3 with value: 0.686887244383494.\n",
      "[I 2025-06-15 13:27:55,577] Trial 5 finished with value: 0.6712962985038757 and parameters: {'window_size': 200, 'step_size': 75}. Best is trial 3 with value: 0.686887244383494.\n",
      "[I 2025-06-15 13:28:34,211] Trial 6 finished with value: 0.6593992213408152 and parameters: {'window_size': 400, 'step_size': 75}. Best is trial 3 with value: 0.686887244383494.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization,DepthwiseConv2D\n",
    "from tensorflow.keras.layers import Activation,AveragePooling2D,Conv2D, RepeatVector, Permute, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tcn import TCN\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_temporal_attention_model(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Conv1D(64, 15, padding='same', activation='relu')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Conv1D(128, 15, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "\n",
    "    # Attention-like mechanism\n",
    "    attention = Dense(1, activation='tanh')(x)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax')(attention)\n",
    "    attention = RepeatVector(128)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "\n",
    "    x = Multiply()([x, attention])\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(make_objective(build_temporal_attention_model), n_trials=20)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(f\"Best accuracy: {study.best_value * 100:.2f}%\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Re-window the data\n",
    "X_train_win, y_train_win = window_data(X_train_augmented, y_train_augmented, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test1_win, y_test1_win = window_data(X_test1_final, y_test1, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test2_win, y_test2_win = window_data(X_test2_final, y_test2, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test3_win, y_test3_win = window_data(X_test3_final, y_test3, study.best_params['window_size'], study.best_params['step_size'])\n",
    "\n",
    "\n",
    "# --- Model Setup ---\n",
    "NUM_CLASSES = len(np.unique(y_train))\n",
    "\n",
    "INPUT_SHAPE = (study.best_params['window_size'], X_train_win.shape[2])\n",
    "temporal_attention_model = build_temporal_attention_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "\n",
    "temporal_attention_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "temporal_attention_model.summary()\n",
    "\n",
    "# --- Training ---\n",
    "temporal_attention_model.fit(\n",
    "    X_train_win,\n",
    "    y_train_win,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on test sets\n",
    "loss1_temporal_attention, acc1_temporal_attention = temporal_attention_model.evaluate(X_test1_win, y_test1_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 1: {acc1_temporal_attention * 100:.2f}%\")\n",
    "loss2_temporal_attention, acc2_temporal_attention = temporal_attention_model.evaluate(X_test2_win, y_test2_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 2: {acc2_temporal_attention * 100:.2f}%\")\n",
    "loss3_temporal_attention, acc3_temporal_attention = temporal_attention_model.evaluate(X_test3_win, y_test3_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 3: {acc3_temporal_attention * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average accuracy: {((acc1_temporal_attention + acc2_temporal_attention +acc3_temporal_attention)/3) * 100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal attention Model Accuracy on Test Set 1: 97.46%\n",
      "temporal attention Model Accuracy on Test Set 2: 25.00%\n",
      "temporal attention Model Accuracy on Test Set 3: 71.48%\n",
      "Average accuracy: 64.65%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test sets\n",
    "loss1_temporal_attention, acc1_temporal_attention = temporal_attention_model.evaluate(X_test1_win, y_test1_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 1: {acc1_temporal_attention * 100:.2f}%\")\n",
    "loss2_temporal_attention, acc2_temporal_attention = temporal_attention_model.evaluate(X_test2_win, y_test2_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 2: {acc2_temporal_attention * 100:.2f}%\")\n",
    "loss3_temporal_attention, acc3_temporal_attention = temporal_attention_model.evaluate(X_test3_win, y_test3_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 3: {acc3_temporal_attention * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average accuracy: {((acc1_temporal_attention + acc2_temporal_attention +acc3_temporal_attention)/3) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-15 13:41:35,350] A new study created in memory with name: no-name-11bbb9f9-9a88-4eef-82a9-53c194993e3e\n",
      "[I 2025-06-15 13:41:49,308] Trial 0 finished with value: 0.710937519868215 and parameters: {'window_size': 100, 'step_size': 150}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:42:11,632] Trial 1 finished with value: 0.7006579041481018 and parameters: {'window_size': 300, 'step_size': 175}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:42:40,795] Trial 2 finished with value: 0.6905637184778849 and parameters: {'window_size': 200, 'step_size': 100}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:43:28,757] Trial 3 finished with value: 0.6412760416666666 and parameters: {'window_size': 400, 'step_size': 100}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:43:38,859] Trial 4 finished with value: 0.6689814925193787 and parameters: {'window_size': 100, 'step_size': 200}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:43:48,619] Trial 5 finished with value: 0.5817307531833649 and parameters: {'window_size': 150, 'step_size': 275}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:44:05,637] Trial 6 finished with value: 0.6973039309183756 and parameters: {'window_size': 250, 'step_size': 200}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:44:37,698] Trial 7 finished with value: 0.6660539309183756 and parameters: {'window_size': 250, 'step_size': 100}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:45:09,140] Trial 8 finished with value: 0.7091049353281657 and parameters: {'window_size': 300, 'step_size': 125}. Best is trial 0 with value: 0.710937519868215.\n",
      "[I 2025-06-15 13:45:28,661] Trial 9 finished with value: 0.7744047443072001 and parameters: {'window_size': 100, 'step_size': 100}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:46:13,687] Trial 10 finished with value: 0.6678743958473206 and parameters: {'window_size': 150, 'step_size': 50}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:46:26,460] Trial 11 finished with value: 0.7005208233992258 and parameters: {'window_size': 100, 'step_size': 150}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:47:00,399] Trial 12 finished with value: 0.7056547602017721 and parameters: {'window_size': 100, 'step_size': 50}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:47:09,482] Trial 13 finished with value: 0.689102570215861 and parameters: {'window_size': 150, 'step_size': 275}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:47:21,743] Trial 14 finished with value: 0.6819444497426351 and parameters: {'window_size': 200, 'step_size': 225}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:47:52,000] Trial 15 finished with value: 0.6628788014252981 and parameters: {'window_size': 400, 'step_size': 150}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:48:26,385] Trial 16 finished with value: 0.6865740617116293 and parameters: {'window_size': 200, 'step_size': 75}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:48:38,257] Trial 17 finished with value: 0.6310764054457346 and parameters: {'window_size': 100, 'step_size': 150}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:48:48,700] Trial 18 finished with value: 0.6888020833333334 and parameters: {'window_size': 150, 'step_size': 225}. Best is trial 9 with value: 0.7744047443072001.\n",
      "[I 2025-06-15 13:49:19,271] Trial 19 finished with value: 0.6874999900658926 and parameters: {'window_size': 350, 'step_size': 125}. Best is trial 9 with value: 0.7744047443072001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'window_size': 100, 'step_size': 100}\n",
      "Best accuracy: 77.44%\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_20\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_20\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tcn_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TCN</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">280,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ tcn_20 (\u001b[38;5;33mTCN\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m280,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,516</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m280,516\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,516</span> (1.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m280,516\u001b[0m (1.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "112/112 - 4s - 36ms/step - accuracy: 0.9280 - loss: 0.5100 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 2/20\n",
      "112/112 - 3s - 28ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 5.7232e-05\n",
      "Epoch 3/20\n",
      "112/112 - 3s - 26ms/step - accuracy: 1.0000 - loss: 5.8929e-04 - val_accuracy: 1.0000 - val_loss: 1.0823e-05\n",
      "Epoch 4/20\n",
      "112/112 - 3s - 26ms/step - accuracy: 1.0000 - loss: 1.7982e-04 - val_accuracy: 1.0000 - val_loss: 6.3349e-06\n",
      "Epoch 5/20\n",
      "112/112 - 3s - 26ms/step - accuracy: 0.9967 - loss: 0.0169 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 6/20\n",
      "112/112 - 3s - 28ms/step - accuracy: 0.9992 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 7.8054e-06\n",
      "Epoch 7/20\n",
      "112/112 - 3s - 27ms/step - accuracy: 1.0000 - loss: 1.1410e-05 - val_accuracy: 1.0000 - val_loss: 7.0750e-06\n",
      "Epoch 8/20\n",
      "112/112 - 3s - 28ms/step - accuracy: 0.9994 - loss: 0.0013 - val_accuracy: 0.9911 - val_loss: 0.0576\n",
      "Epoch 9/20\n",
      "112/112 - 3s - 27ms/step - accuracy: 1.0000 - loss: 4.8579e-05 - val_accuracy: 0.9911 - val_loss: 0.0504\n",
      "Epoch 10/20\n",
      "112/112 - 3s - 28ms/step - accuracy: 1.0000 - loss: 8.1162e-06 - val_accuracy: 0.9911 - val_loss: 0.0481\n",
      "Epoch 11/20\n",
      "112/112 - 3s - 30ms/step - accuracy: 1.0000 - loss: 9.9555e-06 - val_accuracy: 0.9911 - val_loss: 0.0415\n",
      "Epoch 12/20\n",
      "112/112 - 3s - 27ms/step - accuracy: 1.0000 - loss: 3.0312e-05 - val_accuracy: 0.9933 - val_loss: 0.0343\n",
      "Epoch 13/20\n",
      "112/112 - 3s - 31ms/step - accuracy: 1.0000 - loss: 2.9159e-06 - val_accuracy: 0.9933 - val_loss: 0.0313\n",
      "Epoch 14/20\n",
      "112/112 - 3s - 31ms/step - accuracy: 1.0000 - loss: 4.5569e-06 - val_accuracy: 0.9933 - val_loss: 0.0305\n",
      "Epoch 15/20\n",
      "112/112 - 4s - 32ms/step - accuracy: 1.0000 - loss: 7.3027e-06 - val_accuracy: 0.9933 - val_loss: 0.0291\n",
      "Epoch 16/20\n",
      "112/112 - 4s - 33ms/step - accuracy: 1.0000 - loss: 6.6153e-06 - val_accuracy: 0.9933 - val_loss: 0.0259\n",
      "Epoch 17/20\n",
      "112/112 - 3s - 28ms/step - accuracy: 1.0000 - loss: 5.5124e-06 - val_accuracy: 0.9933 - val_loss: 0.0266\n",
      "Epoch 18/20\n",
      "112/112 - 3s - 29ms/step - accuracy: 1.0000 - loss: 2.2910e-06 - val_accuracy: 0.9933 - val_loss: 0.0246\n",
      "Epoch 19/20\n",
      "112/112 - 3s - 28ms/step - accuracy: 1.0000 - loss: 1.1861e-05 - val_accuracy: 0.9933 - val_loss: 0.0174\n",
      "Epoch 20/20\n",
      "112/112 - 3s - 30ms/step - accuracy: 1.0000 - loss: 1.9762e-06 - val_accuracy: 0.9933 - val_loss: 0.0169\n",
      "temporal attention Model Accuracy on Test Set 1: 91.79%\n",
      "temporal attention Model Accuracy on Test Set 2: 18.93%\n",
      "temporal attention Model Accuracy on Test Set 3: 13.93%\n",
      "Average accuracy: 41.55%\n"
     ]
    }
   ],
   "source": [
    "def build_tcn_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        TCN(nb_filters=64, kernel_size=5, dilations=[1, 2, 4, 8, 16], return_sequences=False),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(make_objective(build_tcn_model), n_trials=20)\n",
    "\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(f\"Best accuracy: {study.best_value * 100:.2f}%\")\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Re-window the data\n",
    "X_train_win, y_train_win = window_data(X_train_augmented, y_train_augmented, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test1_win, y_test1_win = window_data(X_test1_final, y_test1, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test2_win, y_test2_win = window_data(X_test2_final, y_test2, study.best_params['window_size'], study.best_params['step_size'])\n",
    "X_test3_win, y_test3_win = window_data(X_test3_final, y_test3, study.best_params['window_size'], study.best_params['step_size'])\n",
    "\n",
    "\n",
    "# --- Model Setup ---\n",
    "NUM_CLASSES = len(np.unique(y_train))\n",
    "\n",
    "INPUT_SHAPE = (study.best_params['window_size'], X_train_win.shape[2])\n",
    "build_tcn_model_model = build_tcn_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "\n",
    "build_tcn_model_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "build_tcn_model_model.summary()\n",
    "\n",
    "# --- Training ---\n",
    "build_tcn_model_model.fit(\n",
    "    X_train_win,\n",
    "    y_train_win,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate on test sets\n",
    "loss1_build_tcn_model, acc1_build_tcn_model = build_tcn_model_model.evaluate(X_test1_win, y_test1_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 1: {acc1_build_tcn_model * 100:.2f}%\")\n",
    "loss2_build_tcn_model, acc2_build_tcn_model = build_tcn_model_model.evaluate(X_test2_win, y_test1_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 2: {acc2_build_tcn_model * 100:.2f}%\")\n",
    "loss3_build_tcn_model, acc3_build_tcn_model = build_tcn_model_model.evaluate(X_test3_win, y_test1_win, verbose=0)\n",
    "print(f\"temporal attention Model Accuracy on Test Set 3: {acc3_build_tcn_model * 100:.2f}%\")\n",
    "\n",
    "print(f\"Average accuracy: {((acc1_build_tcn_model + acc2_build_tcn_model +acc3_build_tcn_model)/3) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = [acc1_build_tcn_model, acc2_build_tcn_model, acc3_build_tcn_model]\n",
    "test_sets = ['Test Set 1', 'Test Set 2', 'Test Set 3']\n",
    "\n",
    "# Plot accuracy bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(test_sets, [a * 100 for a in accuracies], color='skyblue')\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy on Test Sets')\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc * 100 + 1, f\"{acc * 100:.2f}%\", ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
