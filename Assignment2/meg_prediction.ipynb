{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Assignment 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports and Variables\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from scipy.signal import butter, filtfilt, decimate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"Final Project data/Intra/train/\"\n",
    "TEST_PATH = \"Final Project data/Intra/test/\"\n",
    "\n",
    "\n",
    "# data specific\n",
    "NUM_CHANNELS = 248\n",
    "NUM_CLASSES = 4\n",
    "LABEL_MAP = {'rest':0, 'taskmotor':1, 'taskstorymath':2, 'taskworkingmemory':3}\n",
    "\n",
    "\n",
    "# Model specific\n",
    "NUM_EPOCHS = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load and Preprocess Data\n",
    "Apply a lowpass filter for downsampling the frequency"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# lowpass filter\n",
    "def bandpass_filter(data, lowcut=1.0, highcut=150.0, fs=2034, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data, axis=-1)\n",
    "\n",
    "# down sampling data to a lower frequency that still contains usable information\n",
    "def downsample_sample(data, orig_fs=2034, target_fs=250):\n",
    "    factor = int(orig_fs / target_fs)\n",
    "    return decimate(data, factor, axis=-1, ftype='fir', zero_phase=True)\n",
    "\n",
    "\n",
    "def get_dataset_name(filename_with_dir):\n",
    "    filename_without_dir = filename_with_dir.split( '/')[-1]\n",
    "    temp = filename_without_dir.split ('_')[:-1]\n",
    "    dataset_name = \"_\". join(temp)\n",
    "    return dataset_name\n",
    "\n",
    "# get the label from the file name\n",
    "def get_y_from_filename(filename):\n",
    "    split_name = filename.split('_')\n",
    "    return \"\".join(split_name[:-2]).lower()\n",
    "\n",
    "# load data X from the given file\n",
    "def load_data_from_file(file_path):\n",
    "    with h5py.File(file_path , 'r') as f :\n",
    "        dataset_name = get_dataset_name(file_path)\n",
    "        return f.get(dataset_name)[()]\n",
    "\n",
    "# individual min max scaling\n",
    "def min_max_scale_sample(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    flat = data.reshape(-1, 1)\n",
    "    return scaler.fit_transform(flat).reshape(data.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# apply all preprocessing steps to a given file\n",
    "def preprocess_file(filepath):\n",
    "    data = load_data_from_file(filepath)\n",
    "    filtered = bandpass_filter(data)\n",
    "    downsampled = downsample_sample(filtered)\n",
    "\n",
    "    return min_max_scale_sample(downsampled)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. A simple MegNet model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class SimpleMEGNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(SimpleMEGNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_channels, 64, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.adaptive_pool(x).squeeze(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# use cuda if possible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = SimpleMEGNet(NUM_CHANNELS, NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# get all file names form the given folder\n",
    "file_list = [os.path.join(TRAIN_PATH, f) for f in os.listdir(TRAIN_PATH) if f.endswith('.h5')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 45.3717\n",
      "Epoch 2/10, Loss: 44.5509\n",
      "Epoch 3/10, Loss: 42.5294\n",
      "Epoch 4/10, Loss: 40.5417\n",
      "Epoch 5/10, Loss: 36.8453\n",
      "Epoch 6/10, Loss: 32.9748\n",
      "Epoch 7/10, Loss: 28.2415\n",
      "Epoch 8/10, Loss: 22.1935\n",
      "Epoch 9/10, Loss: 18.2981\n",
      "Epoch 10/10, Loss: 11.6083\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # run training per file\n",
    "    for filepath in file_list:\n",
    "        filename = os.path.basename(filepath)\n",
    "        label_str = get_y_from_filename(filename)\n",
    "\n",
    "        y = torch.tensor([LABEL_MAP[label_str]], dtype=torch.long).to(device)\n",
    "        X = preprocess_file(filepath)\n",
    "        input_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_tensor)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {total_loss:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model on testing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "test_files = [os.path.join(TEST_PATH, f) for f in os.listdir(TEST_PATH) if f.endswith('.h5')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.125\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for f in test_files:\n",
    "\n",
    "        # preprocess files\n",
    "        x = preprocess_file(f)\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # get prediction for input\n",
    "        outputs = model(x_tensor)\n",
    "        _, predicted = torch.max(outputs, dim=1)  # TODO try: pred = output.argmax(dim=1).item()\n",
    "\n",
    "        # get true label for the input\n",
    "        filename = os.path.basename(f)\n",
    "        true_label = LABEL_MAP[get_y_from_filename(filename)]\n",
    "\n",
    "        correct += (predicted.item() == true_label)\n",
    "\n",
    "\n",
    "test_accuracy = correct / len(test_files)\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
